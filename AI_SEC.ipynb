{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+mmY+PVPFkGi1DMV1Zjn4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tiagosmartins1/imersaoaluratsm/blob/main/AI_SEC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import hashlib\n",
        "import google.generativeai as genai\n",
        "\n",
        "genai.configure(api_key=\"AIzaSyBflDdhhWVGVO_UFm3vGMGJOv4NxwyWltc\")"
      ],
      "metadata": {
        "id": "csXAW6qFZGzx"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Listando os modelos disponíveis\n",
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "o1gQLf_vZMCH",
        "outputId": "5e467412-011a-44a3-f1c1-a5ceb5479d17"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# aqui consiste na temperatura das respostas, quanto mais proximo do 1, mais aleatório é a respsta, ou seja, sera mais fiel a resposta\n",
        "generation_config = {\n",
        "  \"candidate_count\": 1,\n",
        "  \"temperature\": 0.5,\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "1HrSxV2VZbUf"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Configuraçoes de segurança para resposta\n",
        "safety_settings={\n",
        "    'HATE': 'BLOCK_NONE',\n",
        "    'HARASSMENT': 'BLOCK_NONE',\n",
        "    'SEXUAL' : 'BLOCK_NONE',\n",
        "    'DANGEROUS' : 'BLOCK_NONE'\n",
        "    }"
      ],
      "metadata": {
        "id": "QcYSU7jZZflQ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(model_name='gemini-1.0-pro',\n",
        "                                  generation_config=generation_config,\n",
        "                                  safety_settings=safety_settings,)"
      ],
      "metadata": {
        "id": "GZ6SW6lBZn8j"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\"Que empresa criou o modelo de IA Gemini?\")\n",
        "response.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9D9ROyzSa7rz",
        "outputId": "3b37710e-df14-4204-ccac-06e379ccb705"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Google'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat = model.start_chat(history=[ ])"
      ],
      "metadata": {
        "id": "6x4zD9dBbeh7"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pront  = input(\"Esperando pront: \")\n",
        "\n",
        "while pront != \"fim\":\n",
        "  response = chat.send_message(pront)\n",
        "  print(\"Resposta:\", response.text, 'n')\n",
        "  pront = input('Esperando prompt: ')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "Dp9RYOWbcT8R",
        "outputId": "a64bee1d-af13-4e63-b7a9-45b865d62ded"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Esperando pront: capital do brasil\n",
            "Resposta: Brasília n\n",
            "Esperando prompt: comida tipica\n",
            "Resposta: Feijoada\n",
            "\n",
            "**Ingredientes:**\n",
            "\n",
            "* 500g de feijão preto\n",
            "* 250g de carne seca\n",
            "* 250g de lombo de porco\n",
            "* 250g de paio\n",
            "* 250g de costela de porco\n",
            "* 1 cebola grande picada\n",
            "* 4 dentes de alho picados\n",
            "* 2 folhas de louro\n",
            "* 1 colher (sopa) de óleo\n",
            "* Sal e pimenta a gosto\n",
            "\n",
            "**Para acompanhar:**\n",
            "\n",
            "* Arroz branco\n",
            "* Farofa\n",
            "* Couve refogada\n",
            "* Laranja cortada em gomos\n",
            "\n",
            "**Modo de preparo:**\n",
            "\n",
            "1. Deixe o feijão de molho em água por pelo menos 12 horas.\n",
            "2. Em uma panela de pressão, coloque o feijão escorrido, a carne seca, o lombo de porco, o paio, a costela de porco, a cebola, o alho, o louro, o óleo, o sal e a pimenta.\n",
            "3. Cubra com água e cozinhe por cerca de 40 minutos, ou até que o feijão esteja macio e a carne cozida.\n",
            "4. Retire a panela do fogo e deixe a pressão sair naturalmente.\n",
            "5. Abra a panela e verifique o tempero. Ajuste se necessário.\n",
            "6. Sirva a feijoada acompanhada de arroz branco, farofa, couve refogada e laranja cortada em gomos. n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Melhorando a visualização\n",
        "#Código disponível em https://ai.google.dev/tutorials/python_quickstart#import_packages\n",
        "import textwrap\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
        "\n",
        "#Imprimindo o histórico\n",
        "for message in chat.history:\n",
        "  display(to_markdown(f'**{message.role}**: {message.parts[0].text}'))\n",
        "  print('-------------------------------------------')"
      ],
      "metadata": {
        "id": "oAaBfDxieOCx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}